import requests
import json
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, date
from calendar import monthrange
from dotenv import load_dotenv
import os

# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng m·ªôt l·∫ßn khi module ƒë∆∞·ª£c import
load_dotenv()

class GMVCampaignProductDetailReporter:
    """
    L·∫•y v√† k·∫øt h·ª£p d·ªØ li·ªáu hi·ªáu su·∫•t chi·∫øn d·ªãch v·ªõi th√¥ng tin chi ti·∫øt s·∫£n ph·∫©m
    t·ª´ TikTok Marketing API.
    
    ƒê√£ ƒë∆∞·ª£c n√¢ng c·∫•p v·ªõi c∆° ch·∫ø backoff v√† throttling ƒë·ªÉ tƒÉng ƒë·ªô ·ªïn ƒë·ªãnh.
    """
    # --- C√ÅC H·∫∞NG S·ªê API ---
    BC_API_URL = "https://business-api.tiktok.com/open_api/v1.3/bc/get/"
    PRODUCT_API_URL = "https://business-api.tiktok.com/open_api/v1.3/store/product/get/"
    PERFORMANCE_API_URL = "https://business-api.tiktok.com/open_api/v1.3/gmv_max/report/get/"

    def __init__(self, access_token: str, advertiser_id: str, store_id: str):
        """
        Kh·ªüi t·∫°o reporter.

        Args:
            access_token (str): Access token ƒë·ªÉ x√°c th·ª±c v·ªõi API.
            advertiser_id (str): ID c·ªßa t√†i kho·∫£n qu·∫£ng c√°o.
            store_id (str): ID c·ªßa c·ª≠a h√†ng TikTok Shop.
        """
        if not all([access_token, advertiser_id, store_id]):
            raise ValueError("access_token, advertiser_id, v√† store_id kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.")
            
        self.access_token = access_token
        self.advertiser_id = advertiser_id
        self.store_id = store_id
        
        self.session = requests.Session()
        self.session.headers.update({
            "Access-Token": self.access_token,
            "Content-Type": "application/json",
        })

        # Thu·ªôc t√≠nh cho c∆° ch·∫ø throttling v√† backoff
        self.throttling_delay = 0.0
        self.recovery_factor = 0.8 # Gi·∫£m delay ƒëi 20% sau m·ªói l·∫ßn th√†nh c√¥ng

    # --- PH·∫¶N 1: C√ÅC PH∆Ø∆†NG TH·ª®C TI·ªÜN √çCH V√Ä G·ªåI API C·ªêT L√ïI ---

    def _make_api_request_with_backoff(self, url: str, params: dict, max_retries: int = 6, base_delay: int = 3) -> dict | None:
        """Th·ª±c hi·ªán g·ªçi API v·ªõi c∆° ch·∫ø th·ª≠ l·∫°i (exponential backoff) v√† throttling."""
        if self.throttling_delay > 0:
            print(f" ¬†[THROTTLING] √Åp d·ª•ng delay h√£m t·ªëc {self.throttling_delay:.2f} gi√¢y.")
            time.sleep(self.throttling_delay)
        
        for attempt in range(max_retries):
            try:
                response = self.session.get(url, params=params, timeout=60)
                response.raise_for_status()
                data = response.json()
                
                if data.get("code") == 0: 
                    # Gi·∫£m d·∫ßn delay n·∫øu y√™u c·∫ßu th√†nh c√¥ng
                    self.throttling_delay *= self.recovery_factor
                    if self.throttling_delay < 0.1: self.throttling_delay = 0
                    return data
                
                # X·ª≠ l√Ω c√°c l·ªói c·ª• th·ªÉ t·ª´ API
                error_message = data.get("message", "")
                if "Too many requests" in error_message or "Request too frequent" in error_message:
                    print(f" ¬†[RATE LIMIT] G·∫∑p l·ªói (l·∫ßn {attempt + 1}/{max_retries})...")
                elif "Internal time out" in error_message:
                    print(f" ¬†[TIME OUT] G·∫∑p l·ªói (l·∫ßn {attempt + 1}/{max_retries})...")
                else:
                    print(f" ¬†[L·ªñI API] {error_message}")
                    # Kh√¥ng th·ª≠ l·∫°i v·ªõi c√°c l·ªói kh√¥ng th·ªÉ ph·ª•c h·ªìi
                    if ("permission" not in error_message):
                        raise Exception(f"[L·ªñI API KH√îNG TH·ªÇ PH·ª§C H·ªíI] {error_message}")
                    return None # Tr·∫£ v·ªÅ None cho l·ªói quy·ªÅn truy c·∫≠p
            
            except requests.exceptions.RequestException as e:
                print(f" ¬†[L·ªñI M·∫†NG] (l·∫ßn {attempt + 1}/{max_retries}): {e}")
            
            if attempt < max_retries - 1:
                delay = (base_delay ** (attempt + 1)) + random.uniform(0, 1)
                self.throttling_delay = delay  # K√≠ch ho·∫°t throttling
                print(f" ¬†Th·ª≠ l·∫°i sau {delay:.2f} gi√¢y.")
                time.sleep(delay)

        print(" ¬†[TH·∫§T B·∫†I] ƒê√£ th·ª≠ l·∫°i t·ªëi ƒëa.")
        raise Exception("H·∫øt s·ªë l·∫ßn th·ª≠, vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi ho·∫∑c tr·∫°ng th√°i API v√† th·ª≠ l·∫°i sau.")

    def _fetch_all_pages(self, url: str, params: dict) -> list:
        """L·∫•y d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ c√°c trang c·ªßa m·ªôt endpoint API."""
        all_results, current_page = [], 1
        while True:
            params['page'] = current_page
            data = self._make_api_request_with_backoff(url, params)
            if not data or data.get("code") != 0: break
            
            page_data = data.get("data", {})
            # Linh ho·∫°t l·∫•y list k·∫øt qu·∫£ t·ª´ c√°c key kh√°c nhau
            result_list = page_data.get("list", []) or page_data.get("store_products", [])
            all_results.extend(result_list)
            
            total_pages = page_data.get("page_info", {}).get("total_page", 1)
            print(f" ¬†[PH√ÇN TRANG] ƒê√£ l·∫•y trang {current_page}/{total_pages}...")
            
            if current_page >= total_pages: break
            current_page += 1
            time.sleep(1.2) # Delay nh·ªè gi·ªØa c√°c trang ƒë·ªÉ tr√°nh b·ªã block
        return all_results

    @staticmethod
    def _chunk_list(data, size):
        for i in range(0, len(data), size):
            yield data[i:i + size]

    @staticmethod
    def _generate_monthly_date_chunks(start_date_str, end_date_str):
        start_date = datetime.strptime(start_date_str, '%Y-%m-%d').date()
        end_date = datetime.strptime(end_date_str, '%Y-%m-%d').date()
        chunks = []
        cursor = date(start_date.year, start_date.month, 1)
        while cursor <= end_date:
            _, last_day = monthrange(cursor.year, cursor.month)
            month_end = date(cursor.year, cursor.month, last_day)
            chunks.append({
                'start': max(cursor, start_date).strftime('%Y-%m-%d'),
                'end': min(month_end, end_date).strftime('%Y-%m-%d')
            })
            next_month = cursor.month + 1
            next_year = cursor.year
            if next_month > 12: next_month, next_year = 1, next_year + 1
            cursor = date(next_year, next_month, 1)
        return chunks
        
    # --- PH·∫¶N 2: C√ÅC PH∆Ø∆†NG TH·ª®C L·∫§Y D·ªÆ LI·ªÜU C·ª§ TH·ªÇ ---

    def _get_bc_ids(self) -> list[str]:
        """L·∫•y danh s√°ch BC ID."""
        print(">> B∆∞·ªõc 1A: ƒêang l·∫•y danh s√°ch BC ID...")
        data = self._make_api_request_with_backoff(self.BC_API_URL, params={})
        if data and data.get("code") == 0:
            bc_list = data.get("data", {}).get("list", [])
            bc_ids = [bc["bc_info"]["bc_id"] for bc in bc_list if bc.get("bc_info")]
            print(f"   -> ƒê√£ l·∫•y th√†nh c√¥ng {len(bc_ids)} BC ID.")
            return bc_ids
        print("   -> L·ªói ho·∫∑c kh√¥ng l·∫•y ƒë∆∞·ª£c BC ID.")
        return []

    def _fetch_products_from_bc_id(self, bc_id: str) -> list | None:
        """L·∫•y t·∫•t c·∫£ s·∫£n ph·∫©m cho m·ªôt bc_id c·ª• th·ªÉ b·∫±ng c√°ch s·ª≠ d·ª•ng _fetch_all_pages."""
        print(f">> B∆∞·ªõc 1B: Th·ª≠ l·∫•y s·∫£n ph·∫©m v·ªõi BC ID: {bc_id}...")
        params = {'bc_id': bc_id, 'store_id': self.store_id, 'page_size': 100}
        
        # Th·ª≠ g·ªçi trang ƒë·∫ßu ti√™n ƒë·ªÉ ki·ªÉm tra quy·ªÅn
        first_page_data = self._make_api_request_with_backoff(self.PRODUCT_API_URL, {**params, 'page': 1})
        
        # S·ª¨A L·ªñI T·∫†I ƒê√ÇY: X·ª≠ l√Ω tr∆∞·ªùng h·ª£p `first_page_data` c√≥ th·ªÉ l√† `None`
        if not first_page_data or first_page_data.get("code") != 0:
            error_msg = "Kh√¥ng c√≥ quy·ªÅn ho·∫∑c kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi h·ª£p l·ªá"
            if first_page_data:
                error_msg = first_page_data.get('message', error_msg)
            
            print(f"   -> L·ªói: {error_msg}. BC ID n√†y kh√¥ng h·ª£p l·ªá.")
            return None
        
        # N·∫øu trang ƒë·∫ßu ti√™n OK, ti·∫øp t·ª•c l·∫•y t·∫•t c·∫£ c√°c trang
        print("   -> Quy·ªÅn h·ª£p l·ªá. B·∫Øt ƒë·∫ßu l·∫•y t·∫•t c·∫£ s·∫£n ph·∫©m...")
        return self._fetch_all_pages(self.PRODUCT_API_URL, params)
    
    def _get_product_map(self) -> dict | None:
        """L·∫•y to√†n b·ªô s·∫£n ph·∫©m v√† chuy·ªÉn th√†nh m·ªôt dictionary ƒë·ªÉ tra c·ª©u nhanh."""
        print("\n--- B∆Ø·ªöC 1: L·∫§Y V√Ä CHU·∫®N B·ªä D·ªÆ LI·ªÜU S·∫¢N PH·∫®M ---")
        bc_ids = self._get_bc_ids()
        if not bc_ids:
            return None

        all_products = []
        for bc_id in bc_ids:
            products_list = self._fetch_products_from_bc_id(bc_id)
            if products_list is not None:
                print(f"   => TH√ÄNH C√îNG! T√¨m th·∫•y BC ID h·ª£p l·ªá: {bc_id}. ƒê√£ l·∫•y {len(products_list)} s·∫£n ph·∫©m.")
                all_products = products_list
                break 
        
        if not all_products:
            print("   -> Kh√¥ng t√¨m th·∫•y BC ID n√†o c√≥ th·ªÉ truy c·∫≠p s·∫£n ph·∫©m c·ªßa store n√†y.")
            return None

        print("\n>> B∆∞·ªõc 1C: T·∫°o b·∫£n ƒë·ªì s·∫£n ph·∫©m ƒë·ªÉ tra c·ª©u nhanh...")
        product_map = {p['item_group_id']: p for p in all_products}
        print(f"   -> ƒê√£ t·∫°o b·∫£n ƒë·ªì cho {len(product_map)} s·∫£n ph·∫©m ƒë·ªôc nh·∫•t.")
        return product_map

    def _get_all_campaigns(self, start_date, end_date):
        """L·∫•y t·∫•t c·∫£ campaign trong m·ªôt kho·∫£ng th·ªùi gian."""
        params = {
            "advertiser_id": self.advertiser_id, "store_ids": json.dumps([self.store_id]),
            "start_date": start_date, "end_date": end_date,
            "dimensions": json.dumps(["campaign_id"]),
            "metrics": json.dumps(["campaign_name", "operation_status", "bid_type"]),
            "filtering": json.dumps({"gmv_max_promotion_types": ["PRODUCT"]}), "page_size": 1000,
        }
        items = self._fetch_all_pages(self.PERFORMANCE_API_URL, params)
        return {
            item["dimensions"]["campaign_id"]: item["metrics"]
            for item in items
        }

    def _fetch_data_for_batch(self, campaign_batch, start_date, end_date):
        """L·∫•y d·ªØ li·ªáu hi·ªáu su·∫•t chi ti·∫øt cho m·ªôt l√¥ campaign."""
        batch_ids = list(campaign_batch.keys())
        params = {
            "advertiser_id": self.advertiser_id, "store_ids": json.dumps([self.store_id]),
            "start_date": start_date, "end_date": end_date,
            "dimensions": json.dumps(["campaign_id", "item_group_id", "stat_time_day"]),
            "metrics": json.dumps(["orders", "gross_revenue", "cost", "cost_per_order", "roi"]),
            "filtering": json.dumps({"campaign_ids": batch_ids}), "page_size": 1000,
        }
        perf_list = self._fetch_all_pages(self.PERFORMANCE_API_URL, params)
        
        results = {}
        for cid, info in campaign_batch.items():
            results[cid] = {
                "campaign_id": cid, "campaign_name": info.get("campaign_name"),
                "operation_status": info.get("operation_status"), "bid_type": info.get("bid_type"),
                "performance_data": []
            }
        
        for record in perf_list:
            cid = record["dimensions"]["campaign_id"]
            if cid in results:
                results[cid]["performance_data"].append(record)
        return list(results.values())

    # --- PH·∫¶N 3: PH∆Ø∆†NG TH·ª®C CH√çNH V√Ä G·ªòP D·ªÆ LI·ªÜU ---

    def _enrich_campaign_data(self, campaign_results, product_map):
        print("\n--- B∆Ø·ªöC 3: G·ªòP D·ªÆ LI·ªÜU S·∫¢N PH·∫®M V√ÄO CAMPAIGN ---")
        if not product_map:
            print("   -> C·∫£nh b√°o: Kh√¥ng c√≥ b·∫£n ƒë·ªì s·∫£n ph·∫©m. D·ªØ li·ªáu s·∫Ω kh√¥ng ƒë∆∞·ª£c l√†m gi√†u.")
            return campaign_results
            
        enriched_results = []
        unique_campaigns = {}

        for campaign in campaign_results:
            campaign_id = campaign.get("campaign_id")
            if not campaign_id: continue

            # G·ªôp c√°c record c·ªßa c√πng m·ªôt campaign l·∫°i
            if campaign_id not in unique_campaigns:
                unique_campaigns[campaign_id] = campaign
            else:
                unique_campaigns[campaign_id]["performance_data"].extend(campaign.get("performance_data", []))

        for campaign in unique_campaigns.values():
            if not campaign.get("performance_data"):
                continue
            
            for perf_record in campaign["performance_data"]:
                item_id = perf_record.get("dimensions", {}).get("item_group_id")
                if item_id:
                    perf_record["product_info"] = product_map.get(item_id, {"title": f"Kh√¥ng t√¨m th·∫•y th√¥ng tin cho ID {item_id}"})
            enriched_results.append(campaign)
            
        print("   -> ƒê√£ g·ªôp d·ªØ li·ªáu th√†nh c√¥ng.")
        return enriched_results

    def get_data(self, start_date: str, end_date: str) -> list:
        """
        H√†m ch√≠nh ƒë·ªÉ ch·∫°y to√†n b·ªô quy tr√¨nh: l·∫•y s·∫£n ph·∫©m, l·∫•y hi·ªáu su·∫•t
        chi·∫øn d·ªãch, v√† g·ªôp ch√∫ng l·∫°i.
        """
        # B∆Ø·ªöC 1: L·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m
        product_map = self._get_product_map()
        if not product_map:
            print("Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m. D·ª´ng th·ª±c thi.")
            return []

        # B∆Ø·ªöC 2: L·∫•y d·ªØ li·ªáu campaign
        print("\n--- B∆Ø·ªöC 2: L·∫§Y D·ªÆ LI·ªÜU CAMPAIGN ---")
        date_chunks = self._generate_monthly_date_chunks(start_date, end_date)
        all_campaign_results = []

        for chunk in date_chunks:
            print(f"\n>> X·ª≠ l√Ω chunk: {chunk['start']} to {chunk['end']}")
            campaigns = self._get_all_campaigns(chunk['start'], chunk['end'])
            if not campaigns:
                print("   -> Kh√¥ng c√≥ campaign n√†o trong kho·∫£ng th·ªùi gian n√†y.")
                continue
            
            print(f"   -> T√¨m th·∫•y {len(campaigns)} campaigns. Chia th√†nh l√¥ ƒë·ªÉ x·ª≠ l√Ω...")
            batches = list(self._chunk_list(list(campaigns.items()), 20))
            
            with ThreadPoolExecutor(max_workers=1) as executor:
                future_to_batch = {
                    executor.submit(self._fetch_data_for_batch, dict(batch), chunk['start'], chunk['end']): batch
                    for batch in batches
                }
                for future in as_completed(future_to_batch):
                    try:
                        all_campaign_results.extend(future.result())
                    except Exception as e:
                        print(f"L·ªói khi x·ª≠ l√Ω m·ªôt l√¥: {e}")
                        raise

        # B∆Ø·ªöC 3: G·ªôp d·ªØ li·ªáu
        final_data = self._enrich_campaign_data(all_campaign_results, product_map)
        return final_data

# --- H√ÄM CH√çNH ƒê·ªÇ CH·∫†Y ---
if __name__ == "__main__":
    # --- C·∫§U H√åNH ---
    ACCESS_TOKEN = os.getenv("TIKTOK_ACCESS_TOKEN")
    ADVERTISER_ID = "7137968211592495105"
    STORE_ID = "7494588040522401840"
    START_DATE = "2025-06-01"
    END_DATE = "2025-09-18"

    start_time = time.perf_counter()
    if not ACCESS_TOKEN:
        print("L·ªñI: Vui l√≤ng thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng TIKTOK_ACCESS_TOKEN trong file .env")
    else:
        try:
            reporter = GMVCampaignProductDetailReporter(
                access_token=ACCESS_TOKEN,
                advertiser_id=ADVERTISER_ID,
                store_id=STORE_ID
            )
            enriched_results = reporter.get_data(start_date=START_DATE, end_date=END_DATE)

            if enriched_results:
                print("\n--- B∆Ø·ªöC 4: L∆ØU K·∫æT QU·∫¢ ---")
                output_filename = "GMV_Campaign_product_detail_v2.json"
                with open(output_filename, "w", encoding="utf-8") as f:
                    json.dump(enriched_results, f, ensure_ascii=False, indent=4)
                print(f"   -> ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o file '{output_filename}'")
                
                total_cost = sum(
                    float(perf.get("metrics", {}).get("cost", 0))
                    for campaign in enriched_results
                    for perf in campaign.get("performance_data", [])
                )
                print(f"\nüí∞ T·ªïng chi ph√≠ c·ªßa t·∫•t c·∫£ campaign: {total_cost:,.0f} VND")
            else:
                print("\nKh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë·ªÉ x·ª≠ l√Ω.")

        except ValueError as ve:
            print(f"L·ªói c·∫•u h√¨nh: {ve}")
        except Exception as e:
            print(f"ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën: {e}")

    end_time = time.perf_counter()
    print(f"\n--- HO√ÄN T·∫§T ---")
    print(f"T·ªïng th·ªùi gian th·ª±c thi: {end_time - start_time:.2f} gi√¢y.")